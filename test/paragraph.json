"[ \"How to Generate Insights from PDF Files with Apryse and GPT\", \"content\": \"Professionals in finance, legal, and healthcare know the grind of working through endless bank statements, legal contracts, medical records, and more, trying to pull out something meaningful from reams of unstructured data. Fortunately, we live in an era where Large Language Models (LLMs) are more accessible than ever, and it\\u2019s relatively simple these days to build an AI-powered app that can identify patterns, trends, and connections to aid \\u2014 not replace \\u2014 human teams in making data-driven decisions. The catch? This is only possible if you can reliably extract structured data from unstructured PDFs to begin with. While we can certainly attempt to use any of the several PDF.js-based libraries to extract raw text from PDFs, we\\u2019d never be able to preserve ÃŸdata in tabular format \\u2014 and this is a dealbreaker when processing bank statements, financial reports, insurance documents, and more. The core problem is that PDFs were never designed to be data repositories. Rather, they were meant for consistent display, built to preserve how documents look \\u2014 font, text, raster/vector images, tables, forms, and all \\u2014 across devices and operating systems, instead of being tethered to a structured data model you might be used to working with, like JSON or XML. This lack of an inherent schema turns data extraction into a tricky task, because content in PDFs isn\\u2019t organized logically, but visually. Rule-based templates can partially address this but is a fragile solution that falls apart at scale. Each bank, for example, has its own statement format, and even small design tweaks can throw off template-based extraction. Manually creating and maintaining templates for every bank is impractical \\u2014 after all, a template by definition is static, requiring constant upkeep \\u2014 a poor long-term choice. And without this crucial first step done right, a wall of linear, unformatted text that cannot preserve context is never going to give you results from a non-deterministic LLM reliably, or at scale. I would never stake a business on this. For some time now, I\\u2019ve been looking for an alternative that could combine powerful document processing with a flexible, scalable API (so, not a standalone desktop app) that integrated seamlessly into our development pipeline \\u2014 without the headaches of mandatory customization or constant manual oversight. And because security is paramount, I needed it to be deployable on our own infrastructure. Apryse checked every box. Apryse is an all-in-one native toolkit for document management with a commerical license \\u2014 it provides libraries for web, mobile, client, and server use that cover PDF viewing, annotation, editing, creation, generation, and, most relevant to my needs: data extraction via its server SDK, delivering data in JSON, XML, or even XLSX formats. With Apryse, I can finally shift focus from busywork (data extraction, template maintenance) to building out analytics that drive value at scale. It\\u2019s a reliable backbone for high-volume, data-driven operations. Here\\u2019s what sets it apart: a complex neural network under the hood, using deep learning models to intelligently extract structured data from PDFs. Essentially, the Apryse library uses a pipeline of these models that has \\u201clearnt\\u201d to recognize what tabular data in a PDF would look like \\u2014 grids, columns, rows \\u2014 how they\\u2019re positioned in relation to each other, and how they\\u2019re different from paragraphs of text, raster/vector images, and so on. Initialize the library, feed it a PDF as input, and it\\u2019ll deliver parsed and structured data in a way that reflects its layout on the page \\u2014 identifying tables, headers, footers, rows, and columns, and extracting paragraphs/text content along with its reading order and positional data (bounding box coordinates and baselines). What you get back is highly structured output that makes it possible for your downstream processes to analyze or reformat the data for further insights \\u2014 perfect for ingestion by an LLM in the next stage of our insights pipeline. Let\\u2019s see how this works. First off, make sure you\\u2019re running Node.js 18+, and init a new project. We\\u2019re going to install the core Apryse library, and its Data Extraction module (which contains the neural network we\\u2019ve talked about). We\\u2019ll also get dotenv for our environment variables. You can use your package manager of choice to install the dependencies. Let\\u2019s just use NPM here as that\\u2019s the one most Node.js users have by default. For my LLM needs, I\\u2019ll be using the one I have a subscription for \\u2014 OpenAI. But to keep this tutorial as open-ended as possible, and make sure anyone reading can follow along, we\\u2019ll use the Vercel AI SDK, which is a unified interface that allows you to use (and swap out, with ease) OpenAI, Anthropic, Gemini, and whatever else you have access to \\u2014 even custom ones. Finally, API keys. Put them in an .env file in your project folder. Here\\u2019s what mine looks like. The trial version is good for unlimited non-production use \\u2014 if you\\u2019re okay with a watermark on all generated PDFs. The entry point for our script is quite simple, really. You import the library, use addResourceSearchPath to point to the data extraction add-on (which is, technically, an external resource), and await the extraction of tabular data from an input PDF (bank-statement.pdf in the same directory, here) as a JSON string. If your PDF is password protected, simply set the password in a DataExtractionOptions options object, like so: Oh, and to make sure the Apryse SDK cleans up all in-memory objects once a process has finished running, you should run main() initialized with a PDFNet.runWithCleanup(), which makes our code at the end of the extraction stage look like this: Again, make sure your Apryse API key is set in the .env file, and passed as the second argument to the runWithCleanup function here. When you run this script, it should print out the extracted, deeply structured JSON that we talked about earlier. The next step would be to pass this extracted JSON to an LLM, with a prompt designed to extract insights from it. Start by integrating the Vercel AI SDK to handle requests to your LLM provider. We\\u2019ll write a simple function that takes in the JSON data from the previous step, and sends it to the LLM with a specific prompt we\\u2019ll design for actionable insights. Our scenario is analyzing a bank statement for internal business use (i.e. we want strategic and financial insights for stakeholders), so this sounds like a fine prompt to use, right? Almost there, but not quite. LLMs interpret prompts as text, without a clear separation between user instructions and commands hidden within the underlying text. Imagine malicious text in a PDF that subtly redirects your prompt to overemphasize certain data, potentially skewing your company\\u2019s conclusions towards biased, or even harmful decisions. Not a pretty thought. If this were a traditional application, we\\u2019d just handle user inputs with strict sanitation/validation. Prompts for LLMs though, are harder to secure due to their lack of formal coding structure. But there are some safeguards we can take. Since we already have structured JSON as input, ready to go, we could just put that under an extra JSON field, and tell the LLM to process nothing that isn\\u2019t within that particular key-value pair. The non-determinism of LLMs means you can spend forever fine-tuning this prompt to your needs, but this should do as a baseline. After that, we can import the necessary libraries, and simply pass our LLM the necessary data like this. As you can see, the Vercel AI SDK here makes it very easy to swap out the model you want. Everything else will remain the same except the value for the model property. Putting it all together and cleaning up the code a bit, here\\u2019s what we have. For clarity, I\\u2019ve chosen to write outputs at both stages (the extraction from PDF, as well as the insights generated by the LLM) to files on disk. If something goes wrong, hopefully, that\\u2019ll help you diagnose + fine-tune as needed. Your insights are going to be something similar to this. Pretty neat! Lastly, this is outside the scope of this tutorial, but I\\u2019d be remiss if I didn\\u2019t mention something else: a bank statement is typically a small enough PDF that the structured data Apryse extracts is unlikely to exceed your LLM usage or context limits. OpenAI\\u2019s free tier, for example, has an 8K token context limit, which should comfortably handle most bank statements. But if you need to process larger PDFs, like: Then the JSON output generated can easily exceed token limits for many LLMs, especially if it includes a lot of layout metadata. For these, consider using a RAG (Retrieval-Augmented Generation) approach to break the content into smaller, more relevant chunks. This way, you can index the chunks and retrieve only the parts most relevant to each query, reducing token costs and staying within your model\\u2019s context window. PDF data extraction is a crapshoot \\u2014 often involving cobbling together multiple libraries and fighting with inconsistent output. The deep learning-based Apryse was a refreshingly straightforward solution. The SDK\\u2019s ability to maintain structural fidelity when converting PDFs to JSON \\u2014 preserving everything from table relationships to spatial layout \\u2014 provides the perfect foundation for LLM-powered analysis. No more manual parsing, no more regex gymnastics, and no more guessing at document hierarchy. The developer experience has been exceptional, too. Crystal-clear documentation that answers questions and lets you deep dive into the API to figure out potential use cases you might have, lots of sample code that actually reflects real-world use cases, and of course, it\\u2019s fast. I used it for bank statements, but whether you\\u2019re building financial analysis tools, document processing pipelines, or any application that needs to extract meaningful data from PDFs, Apryse deserves a serious look. It\\u2019s turned what\\u2019s typically a painful development process into a straightforward implementation that lets you focus on building features rather than fighting with document parsing.\"}, {\"title\": \"Building Production-Ready AI Agents with LangGraph: A Real-Life Use Case\", \"content\": \"In my recent blog post, A Developer Guide for Creating a Multi-Modal Chatbot Using LangChain Agents, I discussed the role of AI Agents and demonstrated an implementation using the LangChain framework. While it\\u2019s suitable for proofs of concept (POCs), it falls short for production environments. In this post, I will offer a solution that is more adaptable to a production-grade product. You\\u2019ll learn how to create a scalable, efficient system that\\u2019s better suited for real-world applications, giving you the tools to build more robust AI solutions. The main challenge with LangChain Agents is that they grant full control to a single LLM through one large prompt, which manages the entire workflow. In production environments, more granular control is often required, especially as tasks evolve. So how can we best divide the process into smaller, focused prompts, each responsible for a specific part of the task? This method that I discuss in this post makes it easier to debug and fine-tune each individual component in the flow. Additionally, no single LLM is perfect for every task. It\\u2019s often better to divide the process into smaller tasks and assign the most suitable LLM for each, optimizing both performance and cost. This is where the LangGraph library comes in. It offers fine-grained control over an agent\\u2019s flow and state, essential for building robust, production-ready systems. LangGraph extends LangChain by enabling stateful, multi-actor applications with cyclical graphs, making it easier to build sophisticated, reliable agent runtimes. The main key features in LangGraph are: I built an application that helps plan your next vacation or business trip. Enter a prompt, and the app fetches real-time flight and hotel options, displaying them on a user-friendly web page. If desired, you can also send this information via email. You can find the full code in the Github repository. The AI travel agent uses two main tools: Additionally, the app uses the SendGrid API to send emails. For example, if you input the following prompt: I want to travel to Amsterdam from Madrid from 1 to 7 of October, find me flights and 4-star hotels. The app provides relevant flight and hotel options based on real-time data. You\\u2019ll receive an output that includes logos and links for easy reference. Note: The results are sourced from the Google Flights and Google Hotels APIs, with no intention to promote any specific brand. There\\u2019s also an option to send all the travel data via email. I\\u2019ll explain how this is implemented in the technical section (Hint: it involves the human-in-the-loop feature). Ohh nice, I got all the travel data rendered to HTML in an email: Let\\u2019s break down how an AI agent processes a user\\u2019s travel request in a few simple steps. Imagine a user enters the following prompt: \\u201cI want to travel to Amsterdam from Madrid from 1 to 7 of October, find me flights and 4-star hotels.\\u201d Here\\u2019s what happens next: 2. Task Breakdown: The LLM breaks the request into two smaller tasks: 3. Tools Activated: The agent invokes these tools, providing the correct data (like dates, locations, etc.) as parameters. Each tool runs and outputs the flight and hotel options in a structured format. 4. Processing the Results: The LLM is called again to summarize the results and present them in an easy-to-read format. 5. Email Option: The user is then given an option to email this information. If the user decides to send it via email, they enter details in a form (like the recipient\\u2019s email). 7. Email Sent and Process Ends: Using the previously collected data, the agent resumes from where it left off. It invokes the email-sending function, which delivers the information to the provided email address. Once the email is sent, the agent finishes its task, completing the flow. The input to the Mermaid editor is generated using the following code: To visualize the graph, take the output from this code and enter it into the Mermaid editor online. (Note that the exact visualization may differ slightly depending on the version of LangGraph you\\u2019re using). The code snippet below defines a class that implements the agent, which is responsible for managing tasks and invoking tools using a language model (LLM). Let\\u2019s break down the key concepts of the code provided: This method checks the most recent message in the state to determine the next action. If no more tool calls are needed (i.e., there are no tool calls left in the message), the agent transitions to sending an email. Otherwise, it continues invoking additional tools. In LangGraph terms, this method acts as a Decision Function to decide which path (edge) the agent should take next. This method handles the final step, where the agent sends an email with the results. The agent instantiates another LLM to help draft the email based on the last message in the state. It uses a prompt (template) to guide the LLM in generating the email content. The email is then sent to the user using the SendGridAPIClient. In this method, the agent sends a list of messages to the LLM, which includes a System Message (a predefined prompt instructing the LLM what to do) and previous messages. The LLM then returns a new message, which contains instructions on which tool to invoke next. This new message is added to the state. This method is responsible for actually invoking the tools based on the LLM\\u2019s instructions. The agent checks the last message in the state for tool calls. It loops through these tool requests, ensures the tool is valid, and then invokes the corresponding tool. The results from the tools are returned as Tool Messages and appended to the state. If an invalid tool is requested, the agent prompts the LLM to retry. A crucial part of the agent\\u2019s design is its ability to remember its last state. This is managed by a MemorySaver, which ensures that if the agent needs to pause and resume (e.g., while waiting for the user to decide to send an email), it picks up from the correct point without starting over. There are several options for checkpointers to use in production, such as Postgres, MongoDB, and Redis. In the app.py (which handles the UI code), a unique thread_id is generated for each session to maintain the context of the user\\u2019s interactions. This thread_id is passed along with every call to the agent, ensuring the memory state is preserved across requests. The agent allows human intervention at a critical decision point: Deciding whether or not to send an email with the gathered travel information (flights, hotels, etc). This is managed using the Human-in-the-Loop feature, which pauses the agent\\u2019s execution right before the email is sent, allowing the user to review the results and provide necessary input. Implemented by passing interrupt_before=[\\u2018email_sender\\u2019] in the graph.compile() function. Once the user decides to send the email and submits the data, the following code runs in the UI to complete the process: One of LangGraph\\u2019s key advantages is the flexibility to use multiple LLMs at different stages of the workflow, rather than relying on a single LLM with one large prompt. This allows the agent to select the most suitable LLM based on the current task. For example, you can use one LLM specialized in tool invocation and task processing, and another that is better suited for generating and formatting email content in HTML. Integrating LangChain into your application provides access to its comprehensive suite of tools for building complex, modular workflows with language models. By leveraging LangChain\\u2019s capabilities, you can easily incorporate different LLMs, tools and workflows into your agent\\u2019s functionality. To integrate with LangSmith, simply add these environment variables to your .env file: By breaking tasks into smaller, manageable components, LangGraph allows for easier debugging, flexibility in tool and LLM integration and the inclusion of human-in-the-loop interactions. The AI travel agent example, which helps users find real-time flight and hotel options, showcases LangGraph\\u2019s ability to handle complex workflows, leveraging multiple tools and offering email functionality. It also highlights LangGraph\\u2019s key features, such as persistent state management, multi-step workflows, and seamless integration with LangChain and LangSmith, making it a powerful framework for building robust AI-driven applications.\"}, {\"title\": \"7 Writing Side Hustles That Pay My Rent As A Complete Beginner\", \"content\": \"I never thought I\\u2019d say this, but writing actually pays my rent now. Trust me, I\\u2019m no Shakespeare \\u2014 just someone who discovered these seven writing jobs that don\\u2019t need fancy degrees or years of experience. Remember that time I bought those bright yellow running shoes that looked amazing online but felt like concrete blocks? Well, now I get paid to write honest product reviews so others don\\u2019t make my mistakes. What you\\u2019ll do: Where to start:\"}, {\"title\": \"I Gained 15,000 Followers With These 3 Dead Simple Steps\", \"content\": \"If you want a massive online audience. It\\u2019s not complicated. I started last year. Age 51 with no experience. And have had a wild ride. The route to success is simple but not easy. I\\u2019ve got no fake promises of instant success. But I can give you my 3 steps. These are proven to work. Follow these for a long time and I promise you\\u2019ll end up somewhere good. It takes time to get good. But unless you giftwrap your ideas in an entertaining way. You may as well go home. It\\u2019s tough keeping a reader\\u2019s attention. So commit to learning how. Here\\u2019s how to get good. Work on one micro skill each month. Don\\u2019t try to do everything at once. Learn from the best. Get feedback from someone you respect. And in 6 months you\\u2019ll be an incredible writer. Here are the first 6 micro-skills you need to learn:\"}, {\"title\": \"AI train your face for cheap in 5 minutes (never make images of yourself again)\", \"content\": \"For headshots, social media, pranking\\u2026 use it for anything I made this for a person that I know, so that is why I blurred the eyes out, even though it\\u2019s AI\\u2026 it\\u2019s still super realistic. Even the person to whom I made this got scared, but was amazed at the same time. It was my first time training any LoRas in my entire life. So here is real quick no BS guide on how you can do the same for real\\u2026 real cheap. Flux AI dev version from Flux family here https://replicate.com/collections/flux. File format on all the files should be this: a_photo_of_(yourtriggerword) With lower case letters. The last word has to be connected, no spaces. Put a random trigger word in the end, something not so easy. Collect profile images, full body shots, random face expressions, just be sure that the face is visible but different on each image. 2. Create your account on Replicate and then make a model here: https://replicate.com/create In name you can put the same \\u2018\\u2019trigger\\u2019\\u2019 word that you added on your files as the last part. 3. Let\\u2019s start training: https://replicate.com/ostris/flux-dev-lora-trainer/train Destination should only give you one option, as we created one model in previous step. In images drag your ZIP folder. If it doesn\\u2019t work (happened to me), then extract it from ZIP and put basic folder or rename the folder to something else. Trigger word just the same as you put previously on your file. 4. Add atleast 3\\u20135 dollars at https://replicate.com/account/billing and start training. Training costs like 2\\u20133 dollars. Each image that you will generate will be 4 cents with dev model. But you can switch to schnell model after training, which will take less than a cent per image (quality is worse). 5. Now your 5 minute effort is done. Now we \\u2018\\u2019rest\\u2019\\u2019 for 25 minutes instead (Training time is 25 minutes, just be AFK) Be sure to start your prompts with \\u2018\\u2019photo of (your word)\\u2019\\u2019 and then your description. Add most important words in the beginning, as it can ignore last ones. If it starts to mix genders, then be sure to add \\u2018\\u2019male\\u2019\\u2019 or \\u2018\\u2019female\\u2019\\u2019 into your prompt, somewhere in the beginning. Just pay 2\\u20133 dollars at once for training and then you are good. Later on 4 cents for every image, which is\\u2026 like whatever. You can literally create professional AI headshots with this for Linkedin or any other platform. Just include in the prompt something like \\u2018\\u2019profile image, wearing black suit, smiling, cinematic, studio room\\u2019\\u2019 etc. \\ud83d\\udc7d\\ud83e\\udd2aOr do something goofy, make yourself do a funny face expression while hanging out with an alien. In terms of cost and quality, why not. I have seen these ready made generators, they are quite expensive, as they only give some images with limited options. Here you can just write whatever you wish and you will get it. Just be sure to mention \\u2018\\u2019profile\\u2019\\u2019 or something like that, otherwise it will give you full body image. You can also change the image format. By default it will give 1:1 square ones, which is fine for a profile image. Well then don\\u2019t forget to follow so you won\\u2019t miss anything. =)\"}, {\"title\": \"\\u2018It\\u2019s a Wonderful Life\\u2019 and Wartime America\", \"content\": \"I watched Frank Capra\\u2019s 1946 film It\\u2019s a Wonderful Life every Christmas growing up. I remember the characters, the plot, and the warm feeling it leaves you with at the end as the music fades out, but it wasn\\u2019t until I got older that I realized why it always stuck the landing. Initially released on December 20th 1946 (78 years ago as of 2024), the majority of the film takes place during the same time period it was made, leading it to be an excellent primary source when trying to understand what this decade was like for American society. Wartime brings out a sense of unity in people, and with this film having been released right after the end of WW2, it was the kind of movie people needed. It was also the kind of movie that studios wanted people to need, as its themes of family, small town living, and hope, were things that studios wanted Americans to believe in. The film acts as a time capsule, allowing audiences of today to take a look at what American society looked like at the time. With the film having come out more than 70 years ago, it\\u2019s easy to see the differences between the world generated in the story, and the one of today. While the circumstances have changed, and there are new issues afoot, I believe we can all take\\u2026\"}, {\"title\": \"How I Make Money From Writing About Crypto \\u2014 Without Writing\", \"content\": \"So, you want to use AI to automate crypto content and rake in that passive income, right? Smart move. But maybe you have that feeling that you\\u2019re constantly grinding, putting in hours upon hours creating content, but somehow your bank account doesn\\u2019t show the work you\\u2019ve been putting in? That was me, not too long ago. I\\u2019d see all these crypto people making a killing online and I couldn\\u2019t help but wonder: What do they know that I don\\u2019t? I\\u2019ll be real with you \\u2014 there was a time when I was glued to my screen, trying every possible method to earn an income in the crypto niche. I\\u2019d get up before the sun and then burn the midnight oil, pouring my heart into content, hoping it would drive traffic and somehow translate into dollars. But all I got was exhaustion and frustration. I was doing everything I thought was right, but the income just wasn\\u2019t there. Sound familiar? So, there I was, trying to juggle blog posts, social media, and teach newcomers the ropes of crypto, all while trying to keep my sanity. At one point, I felt like I was on a hamster wheel \\u2014 moving constantly, but getting nowhere. I tried blogging, email marketing, and even some paid ads, but the results were lukewarm at best. Then came the turning point. I discovered something I\\u2019d been missing all along \\u2014 a way to use AI to automate the content creation process and leverage it to generate income that keep working even when I\\u2019m not. But I\\u2019m getting ahead of myself\\u2026 I remember the big \\u201caha\\u201d moment: I realized that while everyone talks about passive income, nobody tells you how exhausting it is to keep creating fresh content to keep that income flowing. I needed a way to consistently generate traffic and income without the constant grind. That\\u2019s when I started experimenting with AI tools and automation. And let me tell you \\u2014 when I connected those dots, it was like someone turned on the lights. Suddenly, I saw a clear path to not just surviving, but scaling up to a whole new level. Imagine waking up to see new email subscribers, affiliate commissions, and course sales \\u2014 all while you were catching up on sleep or sipping coffee on a lazy morning. It\\u2019s not just about the money; it\\u2019s about the freedom that comes with it. Freedom to focus on the projects you actually care about, instead of grinding for scraps. But here\\u2019s the catch: If you don\\u2019t adapt, you risk staying stuck in the same cycle, endlessly creating content without seeing a meaningful return. That\\u2019s where most people burn out. The emotional toll of pouring your soul into something that barely pays off can be crushing. Let\\u2019s walk through it: Listen, if you try to hit everything in crypto, you\\u2019ll end up hitting nothing. You need to niche down like your wallet depends on it (because it does). Ask yourself: which part of crypto lights your fire? Here are some killer options: Got it? Now, take that niche and make it your obsession. Have ChatGPT whip up a name that screams, \\u201cRemember me!\\u201d Your brand needs to stand out like a neon sign in a sea of boring billboards. You need a home for your content \\u2014 a base camp for your audience to keep coming back to. Beehiiv is your go-to for building that sleek, professional blog while growing your email list at the same time. Double whammy. And here\\u2019s the kicker: repost your Beehiiv articles on Medium and leverage their massive publications to get eyeballs on your content. That\\u2019s your shortcut to instant traffic. You\\u2019re expanding your reach with minimal effort. Here\\u2019s where you capture leads like a pro. You need something so good people can\\u2019t help but sign up for it. Examples? I\\u2019ve got you covered: The game here is simple: give away value upfront, then cash in on the backend. The more people see your content, the more they trust you, and the easier it is to monetize. Alright, you\\u2019ve got your setup. Now, let\\u2019s turn that into cash flow. Now that you\\u2019ve got an audience and a lead magnet, it\\u2019s time to monetize: Here\\u2019s how: We\\u2019re stacking streams here. Don\\u2019t settle for one when you can have three \\u2014 or five. Here\\u2019s the juicy part: let Make.com do the heavy lifting so you can focus on scaling. You\\u2019re not in this to become a content slave. Let\\u2019s break it down: Once you set it up, your content works for you, not the other way around. You don\\u2019t need to be a tech genius to do this \\u2014 it\\u2019s all about working smarter, not harder. And if you\\u2019re thinking, \\u201cI\\u2019m not tech-savvy,\\u201d don\\u2019t sweat it. These tools are plug-and-play. Set it up once, and let the machine run. Grow your audience and build more revenue streams. \\u27a2 1.) Create timely research content about new industry events. \\u27a2 2.) Create product review blog posts about top-selling trading courses. \\u27a2 3.) Create and publish long-form blog posts from your trade system notifications to promote your system. \\u27a2 4.) Create deep research articles you can monetize. By now, you\\u2019ve got a system that\\u2019s humming. So, what\\u2019s next? Automate your responses on social media to keep engagement high without burning out. Use Beehiiv to set up email sequences that convert your subscribers into buyers while you sleep. The system keeps feeding itself. Here\\u2019s what happened when I applied this system: The best part? The system keeps scaling without extra effort. I\\u2019ve shared the exact steps I\\u2019m using to make this happen. I am putting all six automation blueprints together into a special training program for crypto authors who want to step up their game using AI writing tools to help generate content. Here is a real-time example! Imagine. That\\u2019s what AI and automation can do for you. Ready to Turn AI Automation into a Crypto Goldmine? You\\u2019ve just seen how a simple automation system can generate passive crypto income \\u2014 no trading stress, no risk, and no endless chart-watching. If you\\u2019ve been looking for a way to grow your crypto stack while you sleep, this is your moment. The good news? You don\\u2019t have to reinvent the wheel. I\\u2019ve laid out the exact steps, tools, and automations that are already working for me. This isn\\u2019t just another hustle \\u2014 it\\u2019s a system you can copy, scale, and enjoy the rewards from. And right now, you can get the Cash Flow from Crypto Content blueprint for $55 off with the promo code \\u201855bucks\\u2019. \\u2705 Zero-Risk Income Potential\\u2705 Full Automation Guides\\u2705 Proven AI Tools & Templates Click Here to Grab the Blueprint and start earning free crypto today. Why wait another day? The AI and crypto markets are booming, Final Words: Start Now, Get Results Sooner Aim for that first dollar of income. Once you see that, you\\u2019ll realize you can make another. If you can earn one dollar online, you can earn 10, and soon 100, or even more. The power of compounding your content is insane. So what are you waiting for? Set up your blog, unleash AI, and watch your income grow. Let\\u2019s go! \\ud83d\\ude80 Leave your thoughts, questions, or success stories too! I love to read them! \\u261b \\ud83d\\udec6 Risk Disclaimer \\ud83d\\udec6 You should not invest money that you cannot afford to lose. This article may contain ai-supported research. Seek advice from a certified independent financial adviser if you have any doubts. Nothing in our training products are a promise or guarantee of earnings.\\ud83d\\udc48\\ud83d\\udc48 \\u2705 Please read our https://introtocryptos.ca/about/terms Crypto Authors: \\u270d Write for us Connect on Facebook, Reddit , Twitter and Linkedin \\ud83d\\udc48\\ud83d\\udc48 Trade safe and keep those losses small. Doug This article contains ai generated research and referral links for some of my absolute favorite business tools for content creators and crypto enthusiasts. If you purchase one of my favorite software tools, I will receive a small commission at no additional charge to you.\"}, {\"title\": \"The Secret Code Google Uses To Monitor Everything You Do Online\\ud83d\\ude32\", \"content\": \"Google now has at least 3 ways to track your search clicks and visits that they hide from you. Have you ever tried to copy a URL directly from Google Search? When I did that a few months ago I unexpectedly got something like this from my clipboard: I curiously visited the page and guess what? It took me straight to the original URL. This cryptic URL turned out to be a middleman that would redirect you to the actual page. But what for? After some investigation, I discovered that this was how Google Search had been recording our clicks and tracking every single visited page. They set custom data- attributes and a mousedown event on each link in the search results page:\"}, {\"title\": \"Get Paid $10,000 Monthly with the Amazon Associates Program\", \"content\": \"Ever wondered how you can earn money by sharing the products you already love? That\\u2019s exactly how I felt when I first discovered Amazon\\u2019s Associate Program. Whether you\\u2019re a blogger, an author, a casual content creator, or just someone who enjoys recommending cool products, it\\u2019s one of the easiest ways to monetize your online presence. And the best part? You don\\u2019t have to sell anything yourself Let me walk you through how it works and share a few tricks I\\u2019ve learned to help you maximize your earnings. When I first heard about Amazon Associates, I thought, \\u201cHey, I already recommend products to my friends, especially books\\u2014why not get paid for it?\\u201d Signing up was surprisingly easy. After that, I started creating affiliate links for things I actually use and love. One of my first links was for a book I was obsessed with at the time, \\u201cIt Ends with Us\\u201d and \\u201cDon\\u2019t Believe Everything You Think.\\u201d Those were my favorite books then. But here\\u2019s the fun part \\u2014 even if someone didn\\u2019t buy that exact book but ended up\\u2026\"}, {\"title\": \"Bluesky and enshittification\", \"content\": \"Next weekend (November 8\\u201310), I\\u2019ll be in Tucson, AZ: I\\u2019m the Guest of Honor at the TusCon science fiction convention. I would like to use Bluesky. They\\u2019ve done a bunch of seriously interesting technical work on moderation and ranking that I truly admire, and I\\u2019ve got lots of friends there who really enjoy it. But I\\u2019m not on Bluesky and I don\\u2019t have any plans to join it anytime soon. I wrote about this in 2023: I will never again devote my energies to building up an audience on a platform whose management can sever my relationship to that audience at will: https://pluralistic.net/2023/08/06/fool-me-twice-we-dont-get-fooled-again/ When a platform can hold the people you care about or rely upon hostage \\u2014 when it can credibly threaten you with disconnection and exile \\u2014 that platform can abuse you in lots of ways without losing your business. In other words, they can enshittify their service: https://pluralistic.net/2024/08/17/hack-the-planet/#how-about-a-nice-game-of-chess I appreciate that the CEO of Bluesky, Jay Graber, has evinced her sincere intention never to enshittify Bluesky and I believe she is totally sincere: https://www.wired.com/story/bluesky-ceo-jay-graber-wont-enshittify-ads/ But here\\u2019s the thing: all those other platforms, the ones where I unwisely allowed myself to get locked in, where today I find myself trapped by the professional, personal and political costs of leaving them, they were all started by people who swore they\\u2019d never sell out. I know those people, the old blogger mafia who started the CMSes, social media services, and publishing platforms where I find myself trapped. I considered they friends (I still consider most of them friends), and I knew them well enough to believe that they really cared about their users. They did care about their users. They just cared about other stuff, too, and, when push came to shove, they chose the worsening of their services as the lesser of two evils. Like: when your service is on the brink of being shut down by its investors, who demand that you compromise on privacy, or integrity, or quality, in some relatively small way, are you really going to stand on principle? What about all the users who won\\u2019t be harmed by the compromise, but will have their communities and online lives shattered if you shut down the company? What about all the workers who trusted you, whose family finances will be critically imperilled if you don\\u2019t compromise, just a little. What about the \\u201cecosystem\\u201d partners who\\u2019ve bet on your service, building plug-ins, add-ons and services that make your product better? What about their employees and their employees\\u2019 families? Maybe you tell yourself, \\u201cIf I do this, I\\u2019ll live to fight another day. I can only make the service better for its users if the service still exists.\\u201d Of course you tell yourself that. I have watched virtually every service I relied on, gave my time and attention to, and trusted, go through this process. It happened with services run by people I knew well and thought highly of. Enshittification can be thought of as the result of a lack of consequences. Whether you are tempted by greed or pressured by people who have lower ethics than you, the more it costs to compromise, the fewer compromises you\\u2019ll make. In other words, to resist enshittification, you have to impose switching costs on yourself. That\\u2019s where federation comes in. On Mastodon (and other services based on Activitypub), you can easily leave one server and go to another, and everyone you follow and everyone who follows you will move over to the new server. If the person who runs your server turns out to be imperfect in a way that you can\\u2019t endure, you can find another server, spend five minutes moving your account over, and you\\u2019re back up and running on the new server: https://pluralistic.net/2023/03/04/pick-all-three/#agonism Any system where users can leave without pain is a system whose owners have high switching costs and whose users have none. An owner who makes a bad call \\u2014 like removing the block function say, or opting every user into AI training \\u2014 will lose a lot of users. Not just those users who price these downgrades highly enough that they outweigh the costs of leaving the service. If leaving the service is free, then tormenting your users in this way will visit in swift and devastating pain upon you. That not only helps you steer clear of rationalizing your way into a bad compromise: it also stops your investors and other people with leverage over you from pressuring you into taking actions that harm your users. These devils only sit on your shoulder, whispering temptations and threats, because they think that you can make things worse without spoiling their investment. They\\u2019re not cruel, they\\u2019re greedy. They will only insist on enshittification that they believe they can profit from. If they understand that forcing you to enshittify the service will send all your users packing and leave them with nothing, they will very likely not force you to wreck your service. And of course, if they are so greedy that they force your hand anyway, then your users will be able to escape. Your service will be wrecked and you\\u2019ll be broke, which sucks for you, but you\\u2019re just one person and your pain is vastly outweighed by the relief for the millions of people who escape your service when it goes sour. There\\u2019s a name for this dynamic, from the world of behavioral economics. It\\u2019s called a \\u201cUlysses Pact.\\u201d It\\u2019s named for the ancient hacker Ulysses, who ignored the normal protocol for sailing through the sirens\\u2019 sea. While normie sailors resisted the sirens\\u2019 song by filling their ears with wax, Ulysses instead had himself lashed to the mast, so that he could hear the sirens\\u2019 song, but could not be tempted into leaping into the sea, to be drowned by the sirens. Whenever you take a measure during a moment of strength that guards against your own future self\\u2019s weakness, you enter into a Ulysses Pact \\u2014 think throwing away the Oreos when you start your diet. There is no such thing as a person who is immune to rationalization or pressure. I\\u2019m certainly not. Anyone who believes that they will never be tempted is a danger to themselves and the people who rely on them. A belief you can never be tempted or coerced is like a belief that you can never be conned \\u2014 it makes you more of a mark, not less. Bluesky has many federated features that I find technically admirable. I only know the CEO there slightly, but I have nothing but good opinions of her. At least one of the board members there, Mike Masnick, is one of my oldest friends and comrades in the fights for user rights. We don\\u2019t agree on everything, but I trust him implicitly and would happily give him the keys to my house if he needed a place to stay or even the password for my computer before I had major surgery. But even the best boards can make bad calls. It was just a couple years ago that we had to picket to stop the board of ISOC\\u2014 where I had several dear old friends and comrades \\u2014 from selling control of every .ORG domain to a shadowy hedge-fund run by mustache-twirling evil billionaires: https://www.eff.org/deeplinks/2020/12/how-we-saved-org-2020-review Bluesky lacks the one federated feature that is absolutely necessary for me to trust it: the ability to leave Bluesky and go to another host and continue to talk to the people I\\u2019ve entered into community with there. While there are many independently maintained servers that provide services to Bluesky and its users, there is only one Bluesky server. A federation of multiple servers, each a peer to the other, has been on Bluesky\\u2019s roadmap for as long as I\\u2019ve been following it, but they haven\\u2019t (yet) delivered it. That was worrying when Bluesky was a scrappy, bootstrapped startup with a few million users. Now it has grown to over 13 million users, and it has taken on a large tranche of outside capital: https://fediversereport.com/on-bluesky-and-enshittification/ Plenty of people have commented that now that a VC is holding Bluesky\\u2019s purse-strings, enshittification will surely follow (doubly so because the VC is called \\u201cBlockchain Capital,\\u201d which, at this point, might as well be \\u201cGrifty Scam Caveat Emptor Capital\\u201d). But I don\\u2019t agree with this at all. It\\u2019s not outside capital that leads to enshittification, it\\u2019s leverage that enshittifies a service. A VC that understands that they can force you to wreck your users\\u2019 lives is always in danger of doing so. A VC who understands that doing this will make your service into an empty \\u2014 and thus worthless \\u2014 server is far less likely to do so (and if they do, at least your users can escape). My publishing process is a lot of work and adding another service to it represents a huge amount of work: https://pluralistic.net/2021/01/13/two-decades/#hfbd But I would leap into Bluesky and gladly taken on all that extra work, every day \\u2014 if I knew that I couldn\\u2019t get trapped there. I don\\u2019t know why Bluesky hasn\\u2019t added the federation systems that would enable freedom of exit to its service. Perhaps there are excellent technical reasons to prioritize rolling out the other systems they\\u2019ve created so far. Frankly, it doesn\\u2019t matter. So long as Bluesky can be a trap, I won\\u2019t let myself be tempted. My rule \\u2014 I don\\u2019t join a service that I can\\u2019t leave without switching costs \\u2014 is my Ulysses Pact, and it\\u2019s keeping me safe from danger I\\u2019ve sailed into too many times before. If you\\u2019d like an essay-formatted version of this post to read or share, here\\u2019s a link to it on pluralistic.net, my surveillance-free, ad-free, tracker-free blog: https://pluralistic.net/2024/11/02/ulysses-pact/#tie-yourself-to-a-federated-mast\"}, {\"title\": \"Four Levels of RAG \\u2014 Research from Microsoft\", \"content\": \"Selecting the right RAG (Retrieval-Augmented Generation) architecture depends primarily on the specific use case and implementation requirements, ensuring the system aligns with task demands. Agentic RAG is set to grow in importance, aligning with the concept of Agentic X, where agentic abilities are embedded within personal assistants, workflows, and processes. Here, the \\u201cX\\u201d represents the boundless adaptability of agentic systems, enabling seamless task automation and informed decision-making across diverse contexts for enhanced organisational efficiency and autonomy. Synthesising diverse document sources is crucial for addressing complex, multi-part queries effectively. The challenge of delivering an accurate RAG implementation includes retrieving relevant data, interpreting user intent accurately, and leveraging LLMs\\u2019 reasoning abilities for complex tasks. Reasoning can be enhanced via an Agentic approach to RAG like ReAct, where a reasoning and act sequence of events are created. Something I found interesting from this study is the fact that it states that there is no single solution that fits all data-augmented LLM applications. In many instances, system underperformance stems from either failing to pinpoint the main focus of a task or from tasks that require a combination of skills, which must be carefully separated for optimal results. Directly request specific, known facts. Queries are about explicit facts directly present in the given data without requiring any additional reasoning. This is the simplest form of query, where the model\\u2019s task is primarily to locate and extract the relevant information. When a user asks a question, the RAG implementation targets a fact contained in the chunked data. Seek facts indirectly, needing interpretation to identify the answer. Queries are about implicit facts in the data, which are not immediately obvious and may require some level of common sense reasoning or basic logical deductions. The necessary information might be spread across multiple segments or require simple inferencing. For instance, the question What is the majority party now in the country where Canberra is located? can be answered by combining the fact that Canberra is in Australia with the information about the current majority party in Australia. In level two we start to see the introduction of reasoning and action elements, hence a more agentic approach to RAG. Focus on understanding reasoning behind facts and require data that supports logical explanation. These queries require both factual knowledge and the ability to interpret and apply specific domain-based guidelines that are essential to the context of the data. Such rationales are often provided in external resources but are rarely encountered in the initial pre-training of a general language model. For example, in financial auditing, an LLM may need to follow regulatory compliance guidelines to assess if a company\\u2019s financial statements meet standards. Similarly, in technical support, it may need to follow troubleshooting workflows to assist users, ensuring responses are precise and align with established protocols. Seek deeper insights, often requiring context-based reasoning to uncover underlying meanings or implications. This category of queries requires the AI to infer complex rationales that aren\\u2019t explicitly documented, relying on patterns and outcomes observed within the data. These hidden rationales involve implicit reasoning and logical connections that are challenging to pinpoint and extract. For instance, in IT operations, a language model might analyse patterns from past incident resolutions to identify successful strategies. Similarly, in software development, the AI could draw on past debugging cases to infer effective problem-solving methods. By synthesising these implicit insights, the model can deliver responses that reflect nuanced, experience-based decision-making. Interpretable and Hidden Rationales shift the focus to a RAG system\\u2019s ability to understand and apply the reasoning behind the data. These levels require deeper cognitive processes, where the Agentic Framework aligns with expert knowledge or extracts insights from unstructured historical data. According to the study and considering the image above, there is a distinction between queries requiring explicit facts and those dependent on implicit reasoning. For example, a query about visa eligibility requires clear facts from the consulate\\u2019s guidelines (L3), while a question about the economic impact on a company\\u2019s future development demands an analysis of financial reports and economic trends (L4). The data dependency in both cases underscores the importance of external sources \\u2014 whether official documentation or expert analysis. In both cases, providing rationales helps contextualise responses, offering not just answers but informed reasoning behind them. Chief Evangelist @ Kore.ai | I\\u2019m passionate about exploring the intersection of AI and language. From Language Models, AI Agents to Agentic Applications, Development Frameworks & Data-Centric Productivity Tools, I share insights and ideas on how these technologies are shaping the future.\"}, {\"title\": \"Apple Finally Got a Permanent Replacement for Adobe Photoshop and Illustrator\", \"content\": \"The breakup letter I never thought I\\u2019d write. Photoshop and Illustrator have been my go-to tools for ages. They\\u2019ve been the best for photo editing and graphic design, you name it. But Adobe has had the creative world in their grasp for years, and they\\u2019ve become complacent. Then there\\u2019s Apple. They have this knack for creating tools that feel like they\\u2019re meant to be on your Mac. That\\u2019s exactly how Pixelmator Pro feels \\u2014 it\\u2019s smooth, quick, and fits right into the Apple ecosystem. For years, I stuck with Adobe\\u2019s clunky apps, slow performance, and crazy subscription fees because, well, I didn\\u2019t think there was another option. But when I found Pixelmator Pro, everything changed. It felt like the tool I\\u2019d been dreaming of. And let me tell you, canceling my Adobe subscription was the best decision I\\u2019ve made in ages. Adobe\\u2019s dominance has led to stagnation. Photoshop and Illustrator haven\\u2019t had groundbreaking updates in years. Instead, Adobe keeps piling on features that many users never asked\\u2026\"}, {\"title\": \"My Simple Content Formula That Generates $9,500 Monthly From Writing\", \"content\": \"I messed up badly when I first started writing online. My bank account was empty, and I spent hours writing articles nobody read. But after lots of trial and error (and too much coffee), I stumbled onto a content formula that now brings in $9,500 monthly. The secret? Writing stuff people want to read. Mind-blowing, right? Here\\u2019s my exact process, no fluff: I grab my phone and write down every annoying problem I face. Last week, I couldn\\u2019t figure out how to remove coffee stains from my favorite shirt, so that became an article. Your daily struggles are content gold. Money tip: Search \\u201c[your problem] + affiliate program\\u201d to find products that solve these issues. Companies pay good money when you recommend their solutions. Example: Problem: Coffee stains Article: \\u201cRemove Coffee Stains From Clothes (Tested 8 Methods)\\u201d Product: Special stain remover ($15 commission\\u2026\"}, {\"title\": \"Still using the \\u2018You are an expert\\u2026 \\u2019 AI prompt Part 2\", \"content\": \"Thanks for 20k reads on part 1. I decided to write part 2 since you all loved the first one so much. AI has infinite potential and every day I find a new way to use it that surprises me. Here are 11 more ways to use AI that are genuinely helpful. Type \\u201c/\\u201d and a reason option will appear. You can add your prompt after that to use o1 for completely free. Everyone loved the web search trick from the last post now chatGPT provides a better way to do it. Type \\u201c/\\u201d and a search option will appear. Instead of prompting directly, first ask AI to improve your prompt. Then, use the refined prompt to get better answers. This will save you a lot of attempts when\\u2026\"}, {\"title\": \"The second Gilded Age: Why the 2020s feel like the 1890s\", \"content\": \"\\ud83d\\udc4b Welcome back to the Medium NewsletterIssue #225: an ode to details + the Three-Round Rule of Editing Let\\u2019s rewind to 1876. On Valentine\\u2019s Day that year, a quirky inventor in Boston submitted a patent for what would become the phone. He wasn\\u2019t the only one\\u2014Elisha Gray submitted a similar patent the same day, and contested Bell\\u2019s. Patents in the late 1800s grew nearly 400% (and so did patent litigation). That was the beginning of the Gilded Age (roughly 1870 to 1900 in the U.S.), a period of explosive economic, cultural, and technological change in nearly every dimension of life. New tools changed how we connect, communicate, and make art: the telephone, phonograph, trains, cars, the Kodak camera. The creators of these tools (or those who built infrastructure to help them scale) lived in Gothic villas with armies of staff that insulated them from the world. The top 4,000 families in the U.S. were as rich as everyone else combined. Today, instead of the telephone and phonograph, we have lightning-fast user-generated video and AI-enhanced art. Instead of The Breakers, industry titans live in hyperminimalist glass-and-concrete mansions in northern California. Global income inequality is even more pronounced than it was 150 years ago. In the U.S., income inequality is higher than in any of the G7 nations. The divide between the <1% and everyone else is getting wider. Mark Twain, who coined the term \\u201cGilded Age\\u201d in an 1870s satirical novel, chose the word \\u201cgilded\\u201d instead of \\u201cgold\\u201d to signify that the sheen was only skin deep, like body paint instead of lasting wealth. Underneath the surface of progress and glamour, a lot of people were unhappy and angry. Anarchists expressed their rage by throwing bombs and assassinating industrialists. Railroad workers went on strike, and so did farmers. The parallels between then and now, once you\\u2019re aware of them, are hard to unsee: lookalike contests (a form of cheap entertainment that imitates/idolizes people in power) in place of small-town Vaudeville impersonators; the assassination of UnitedHealth CEO Brian Thompson and its revolution-tinged fallout, an echo of the attempted assassination of anti-union steel magnate Henry Clay Frick by a labor activist; the rise of labor unions \\u2014 which some credit as helping to end the first Gilded Age. I\\u2019m borrowing some of this argument from sociologist Zeynep Tufekci, but I\\u2019ve been thinking about it a lot lately. Is this what it feels like to live through the second Gilded Age? \\u2014 Harris Sockel Everything you write deserves three rounds of edits. The first round is for you, second round is for your fans, and third round is for your haters. (Neil Strauss via Tony Stubblebine) Deepen your understanding every day with the Medium Newsletter. Sign up here. Edited and produced by Scott Lamb & Carly Rose Gillis Questions, feedback, or story suggestions? Email us: tips@medium.com Like what you see in this newsletter but not already a Medium member? Read without limits or ads, fund great writers, and join a community that believes in human storytelling.\"}]"